# ğŸ“Š ClusteringVariables: R Package for Variable Clustering & Analysis

> **This project is conducted as part of the Data Science curriculum at the University of Lyon 2, Master 2 SISE. Its main objective is to develop an R package and a Shiny application capable of performing variable clustering on any given dataset. Users can install the R package directly from GitHub or access the Shiny application to explore and test the package's functionalities.


[![R Version](https://img.shields.io/badge/R-%E2%89%A5%204.0.0-blue)](https://www.r-project.org/)
[![Tests](https://img.shields.io/badge/tests-203%20passing-success)](#)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

---
## ğŸ“‘ Table of Contents

- [ğŸ” Overview](#-overview)
- [âœ¨ Key Features](#-key-features)
- [ğŸ“¦ Installation](#-installation)
- [ğŸš€ Quick Start Guide](#-quick-start-guide)
  - [K-Means for Quantitative Variables](#1-k-means-for-quantitative-variables)
  - [HAC for Qualitative Variables](#2-hac-for-qualitative-variables)
  - [VarClus for Quantitative Variables](#3-varclus-for-quantitative-variables)
- [ğŸ“ŠDatasets included](#-datasets-included)
- [ğŸ”§FonctionnalitÃ©s avancÃ©es](#-fonctionnalitÃ©s-avancÃ©es)
- [ğŸ¨ Shiny Application](#-)
- [ğŸ§ªTests](#-tests)
- [ğŸ› ï¸ Package structure](#-contributions)
- [â“ Getting Help](#-getting-help)
- [ğŸ‘¥ Authors](#-authors)
- [ğŸ“„ License](#-license)

---
## ğŸ” Overview

When we talk about clustering, we're often considering grouping data points (individuals) into clusters. However, it is also valuable to study relationships between variables themselves; analyzing correlations and grouping them based on their shared characteristics. Clustering variables helps understand the underlying structure of your data by revealing which variables behave similarly, identifying redundant features, and enabling feature selection to reduce model complexity.

Therefore, we developed the `ClusteringVariables` package. It is an R package built with R6 classes that provides methods for clustering both quantitative and qualitative variables. The package offers 3 methods for classifying variables:

* ğŸ”„ **KMeans** - Clusters quantitative variables using a reallocation algorithm that iteratively assigns variables to clusters
* ğŸŒ³ **VarClus** - Clusters quantitative variables using a divisive (top-down) hierarchical method that recursively splits variable groups
* ğŸ”— **HAC (Hierarchical Agglomerative Clustering)** - Designed for qualitative variables, it uses an agglomerative (bottom-up) hierarchical approach that progressively merges similar variables, we use their modalities to cluster the variables.

## âœ¨ Key Features

- ğŸ¯ **Three Specialized Algorithms** - KMeans, VarClus, and HAC for different data types
- ğŸ“ˆ **Rich Visualizations** - Dendrograms, heatmaps, elbow plots, correlation circles, etc.
- ğŸ”® **Predictive Capability** - Assign new variables to existing clusters
- ğŸ¨ **Interactive Shiny App** - User-friendly interface for data exploration
- ğŸ“¦ **Clean API** - R6 class-based architecture with unified interface
- ğŸš€ **Automatic Selection** - Built-in methods for optimal cluster determination
- ğŸ“Š **Comprehensive Results** - Detailed summaries and cluster statistics

## ğŸ“¦ Installation

### From GitHub

```r
# Installation de devtools si nÃ©cessaire
if (!require("devtools")) install.packages("devtools")

# Installation du package
devtools::install_github("maissaladjimi/SISE_Clustering_Variables_R", ref = "test_module")
```

### Installation locale

```r
# Depuis le rÃ©pertoire du package
devtools::install()
```

### DÃ©pendances

Le package nÃ©cessite :
- `R6`, `Hmisc`, `ade4`, `dendextend`, `plotly`, `shiny`
- Pour les applications Shiny : `shinyjs`, `shinythemes`

---

## ğŸ¯ Algorithms

**ClusteringVariables** propose trois approches complÃ©mentaires pour le clustering de variables :

| MÃ©thode | Type de variables | Principe | Usage |
|---------|------------------|----------|-------|
| **K-Means Variables** | Quantitatives | Partitionnement par centres mobiles | Groupes de variables corrÃ©lÃ©es |
| **ACM-CAH** | Qualitatives | ACM + Classification hiÃ©rarchique | ModalitÃ©s similaires |
| **VarClus** | Quantitatives | HiÃ©rarchique basÃ© sur corrÃ©lations | Structure arborescente |

---

## ğŸš€ Guide de dÃ©marrage rapide

### ğŸ”„1. K-Means pour variables quantitatives

**Objectif** : Regrouper des variables numÃ©riques fortement corrÃ©lÃ©es.

#### Exemple complet avec le dataset `crime`

```r
library(ClusteringVariables)

# Chargement des donnÃ©es
data(crime)
head(crime, 3)
#   CrimeRate Male14-24 Southern Education Expend60 Expend59 Labor ...
# 1      79.1       151        1         91       58       56   510 ...
# 2     163.5       143        0        113      103       95   583 ...
# 3      57.8       142        1         89       45       44   533 ...

# Dimensions
dim(crime)
# [1] 47 14  # 47 Ã‰tats Ã— 14 variables socio-Ã©conomiques
```

#### Clustering avec K-Means

**Note** : On exclut `CrimeRate` du clustering pour l'utiliser comme variable illustrative.

```r
# SÃ©parer CrimeRate du reste
crime_vars <- crime[, -1]  # Toutes sauf CrimeRate

# Initialisation avec 4 clusters (optimal d'aprÃ¨s l'elbow)
km <- KMeansVariablesQuant$new(k = 4, n_init = 20, seed = 42)

# Ajustement du modÃ¨le
km$fit(crime_vars)

# RÃ©sumÃ© des rÃ©sultats
km$summary()
# ========================================
#   K-MEANS CLUSTERING OF VARIABLES
# ========================================
# Number of variables: 13
# Number of clusters: 4
# Total inertia: 10.5785
# ...
```

## InterprÃ©tation

Les rÃ©sultats montrent 4 clusters de variables :

- **Cluster 1** : Variables de dÃ©penses (Expend60, Expend59)
- **Cluster 2** : Variables socio-dÃ©mographiques (Education, Southern, Male14-24, etc.)
- **Cluster 3** : Variables Ã©conomiques/emploi
- **Cluster 4** : Variables de population

Chaque cluster regroupe des variables fortement corrÃ©lÃ©es entre elles.

#### Visualisations

```r
# Cercle de corrÃ©lation
km$plot_correlation_circle()

# Biplot des variables
km$plot_biplot()

# MÃ©thode du coude pour choisir k
km$plot_elbow(k_range = 2:6)
# === K-Means Elbow Analysis ===
# Optimal k: 4
```

#### PrÃ©diction sur nouvelles variables

```r
# PrÃ©dire le cluster d'une nouvelle variable corrÃ©lÃ©e au crime
new_var <- data.frame(
  Unemployment = rnorm(nrow(crime), mean = 6, sd = 2)
)

# PrÃ©diction
predictions <- km$predict(new_var)
# Warning: 1 variable(s) have RÂ² < 30%: Unemployment
# These variables are poorly represented by existing clusters.

print(predictions)
#                 variable cluster r2_max distance
# Unemployment Unemployment       1  0.037   0.981

```

#### Variables illustratives

```r
# Utiliser CrimeRate comme variable illustrative
crime_rate_df <- data.frame(CrimeRate = crime$CrimeRate)

result <- km$illustrative(crime_rate_df, plot = TRUE)
print(result$table)
#           variable cluster r2_max distance
# CrimeRate CrimeRate       4  42.28   0.7597

# InterprÃ©tation : 
# - CrimeRate est le mieux reprÃ©sentÃ© par le Cluster 4 (RÂ² = 42.28%)
# - distance = 0.76 indique une corrÃ©lation modÃ©rÃ©e avec ce cluster
# - Le Cluster 4 contient probablement des variables socio-Ã©conomiques liÃ©es au crime
```

---

### ğŸ”— 2. ACM-CAH pour variables qualitatives

**Objectif** : Regrouper des modalitÃ©s de variables qualitatives.

#### Exemple avec le dataset `vote`

```r
data(vote)
head(vote, 3)
#   affiliation budget physician salvador nicaraguan missile education
# 1  republican      n         y        y          n       n         y
# 2  republican      n         y        y          n       n         y
# 3    democrat      y   neither        y          n       n         n

# Structure
str(vote)
# 'data.frame': 435 obs. of 7 variables:
#  $ affiliation: Factor w/ 2 levels "democrat","republican": 2 2 1 ...
#  $ budget     : Factor w/ 3 levels "n","neither","y": 1 1 3 ...
```

#### Clustering avec ACM

**Note** : On exclut la variable `affiliation` (parti politique) pour l'utiliser comme variable illustrative et pour les prÃ©dictions.

```r
# SÃ©parer affiliation du reste
vote_vars <- vote[, -1]  # Toutes les variables sauf affiliation

# MÃ©thode ACM (Analyse des Correspondances Multiples)
cm <- ClustModalities$new(method = "acm", n_axes = 5)
cm$fit(vote_vars, k = 3)

# RÃ©sumÃ©
cm$summary()
# ========================================
# CLUSTERING OF QUALITATIVE MODALITIES
# ========================================
#   Method: ACM
#
# Data:
# - Observations              : 435
# - Categorical variables     : 6
# - Total modalities          : 18
#
# Clustering:
# - Number of clusters (k)    : 3
#
# Cluster sizes:
# - Cluster 1                 : 6 modalities
# - Cluster 2                 : 6 modalities
# - Cluster 3                 : 6 modalities
```

#### Visualisations ACM

```r
# Dendrogramme
cm$plot_dendrogram(k = 3)

# Plan factoriel
cm$plot_factorial_map(dims = c(1, 2))

# Ã‰boulis des valeurs propres
cm$plot_scree()

# Contribution des modalitÃ©s
cm$plot_contrib(dim = 1, top = 10)
```

#### MÃ©thode DICE (alternative)

La mÃ©thode DICE utilise l'indice de similaritÃ© de Dice au lieu de l'ACM :

```r
# Clustering basÃ© sur l'indice de DICE
cm_dice <- ClustModalities$new(method = "dice")
cm_dice$fit(vote_vars, k = 3)

cm_dice$summary()
# ========================================
#   QUALITATIVE VARIABLES CLUSTERING
# ========================================
# Method: DICE + CAH
# Number of modalities: 18
# Number of clusters: 3

# Dendrogramme
cm_dice$plot_dendrogram(k = 3)

# Comparaison des deux mÃ©thodes
cat("\n=== Comparaison ACM vs DICE ===\n")
print("ACM : BasÃ© sur l'analyse factorielle des correspondances")
print("DICE : BasÃ© sur l'indice de similaritÃ© (simple, intuitif)")
```

#### PrÃ©diction sur nouvelles observations

```r
# Exemple : utiliser 'affiliation' (parti politique) comme nouvelle variable
affiliation_df <- data.frame(affiliation = vote$affiliation)

predictions <- cm$predict(affiliation_df)
print(predictions)
#                                       modality cluster   distance
# affiliation.republican affiliation.republican       1 0.09164179
# affiliation.democrat     affiliation.democrat       3 0.19380920
```

**Note** : La mÃ©thode predict() de ACM-CAH nÃ©cessite le mÃªme nombre d'observations que l'apprentissage. Voir la documentation pour plus de dÃ©tails.

#### Variables illustratives

**Variable qualitative** : Utiliser `affiliation` (parti politique) comme illustrative

```r
# Affiliation comme variable illustrative (version dÃ©taillÃ©e)
affiliation_df <- data.frame(affiliation = vote$affiliation)
result_parti <- cm$illustrative(affiliation_df, plot = TRUE)
print(result_parti$table)

# InterprÃ©tation :
# - Les modalitÃ©s "democrat" et "republican" sont projetÃ©es sur les clusters
# - On voit quel cluster est le plus associÃ© Ã  chaque parti
# - Cela illustre les profils de vote selon l'affiliation politique
```

---

### ğŸŒ³ 3. VarClus pour clustering hiÃ©rarchique

**Objectif** : Clustering hiÃ©rarchique de variables avec mesures de similaritÃ©.

#### Exemple avec le dataset `uscrime`

```r
data(uscrime)
head(uscrime, 3)
#      M So   Ed  Po1  Po2    LF  M.F Pop   NW    U1   U2 Wealth Ineq   Prob  Time Crime
# 1 15.1  1  9.1  5.8  5.6 0.510 95.0  33 30.1 0.108  4.1   3940 26.1 0.0846 26.20   791
# 2 14.3  0 11.3 10.3  9.5 0.583 101.2 13 10.2 0.096  3.6   5570 19.4 0.0296 25.30  1635
# 3 14.2  1  8.9  4.5  4.4 0.533 96.9  18 21.9 0.094  3.3   3180 25.0 0.0834 24.30   578

dim(uscrime)
# [1] 47 16  # 47 Ã‰tats Ã— 16 variables socio-Ã©conomiques
```

#### Clustering avec VarClus

```r
# Initialisation (similaritÃ© Pearson par dÃ©faut)
vc <- VarClus$new(similarity = "pearson", n_clusters = 4)

# Ajustement
vc$fit(uscrime)

# RÃ©sumÃ© dÃ©taillÃ©
vc$summary()
# ========================================
# VARCLUS - VARIABLE CLUSTERING
# ========================================
# Similarity: pearson

# Status: Model fitted

# Data:
# - Number of variables       : 16
# - Number of clusters        : 4

# Cluster sizes:
# - Cluster 1                 : 6 variables
# - Cluster 2                 : 4 variables
# - Cluster 3                 : 4 variables
# - Cluster 4                 : 2 variables
```

#### Visualisations

```r
# Dendrogramme hiÃ©rarchique
dend_func <- vc$get_dendrogram()
dend_func()

# Heatmap de similaritÃ©
heatmap_func <- vc$get_heatmap()
heatmap_func()
```

#### PrÃ©diction

```r
# PrÃ©dire le cluster d'une nouvelle variable
new_var <- rnorm(nrow(uscrime))
prediction <- vc$predict(new_var)

print(prediction)
# $predicted_cluster
# [1] 4
# 
# $cluster_similarity
#    1     2     3     4 
# 0.143 0.095 0.222 0.409 
#
#  $var_corr
#     variable correlation
# U1       U1       0.327
# U2       U2       0.490
# ...
```

#### Variables illustratives

```r
illust_vars <- data.frame(
  GDP = rnorm(nrow(uscrime), mean = 50000, sd = 10000),
  Temperature = rnorm(nrow(uscrime), mean = 15, sd = 5)
)

result <- vc$illustrative(illust_vars)
print(result$table)
```

#### Changer le nombre de clusters

```r
# Re-dÃ©couper avec un nombre diffÃ©rent de clusters
vc$n_clusters <- 5
vc$fit(uscrime)

vc$summary()
# Nombre de clusters: 5
```

#### Utiliser Spearman au lieu de Pearson

```r
vc_spearman <- VarClus$new(similarity = "spearman", n_clusters = 4)
vc_spearman$fit(uscrime)
```

---

## ğŸ“Š Datasets inclus

Le package inclut 6 datasets prÃªts Ã  l'emploi :

| Dataset | Dimensions | Type | Description |
|---------|-----------|------|-------------|
| **crime** | 47 Ã— 14 | Quantitatif | Statistiques de criminalitÃ© par Ã‰tat US |
| **uscrime** | 47 Ã— 16 | Quantitatif | Variables socio-Ã©conomiques et criminalitÃ© |
| **autos** | 18 Ã— 9 | Mixte | CaractÃ©ristiques de vÃ©hicules (7 num, 2 cat) |
| **autos2005** | 38 Ã— 13 | Mixte | VÃ©hicules 2005 (9 num, 4 cat) |
| **loisirs** | 8403 Ã— 23 | Qualitatif | EnquÃªte pratiques de loisirs (1 num, 22 cat) |
| **vote** | 435 Ã— 7 | Qualitatif | Votes du CongrÃ¨s US 1984 |

**AccÃ¨s aux datasets** :

```r
# Lister tous les datasets
data(package = "ClusteringVariables")

# Charger un dataset
data(crime)
?crime  # Voir la documentation
```

---

## ğŸ”§ FonctionnalitÃ©s avancÃ©es

### MÃ©thode du coude automatique

Les algorithmes proposent une dÃ©tection automatique du nombre optimal de clusters (la proposition de k optimal peut Ãªtre fausse, le plus fiable est de rÃ©fÃ©rer Ã  l'elbow plot pour choisir k) :

```r
# K-Means
data(crime)
crime_vars <- crime[, -1]  # Exclure CrimeRate

km <- KMeansVariablesQuant$new(k = 4)
km$fit(crime_vars)
elbow_result <- km$plot_elbow(k_range = 2:8)
print(elbow_result$optimal_k)  # k optimal suggÃ©rÃ© : 4

```

### RÃ©cupÃ©rer les clusters

```r
# K-Means et VarClus
clusters_table <- km$get_clusters_table()
print(clusters_table)
#       variable cluster
# 10  Unemp14-24       1
# 11  Unemp35-39       1
# 6        Labor       2
# 7         Male       2
# 5     Expend59       3
# 4     Expend60       3
# 8      PopSize       3
# 3    Education       4

# ACM-CAH
clusters_table <- cm$get_clusters_table()  
```

### QualitÃ© du clustering

#### K-Means : Inertie et RÂ²

```r
results <- km$summary(print_output = FALSE)

# Inertie totale
print(results$global_quality)

# RÂ² par variable
print(results$cluster)
#   Cluster Size Inertia Avg_R2.Var1 Avg_R2.Freq  
#1       1    2  1.7459           1      0.8730   
#2       2    2  1.5136           2      0.7568   
#3       3    3  2.3843           3      0.7948   
#4       4    6  4.4051           4      0.7342   
# ...

# CorrÃ©lation entre composantes latentes
print(results$cor_latent)
```

#### VarClus : RÂ² et PCA

```r
results <- vc$summary(print_output = FALSE)

# QualitÃ© par cluster
print(results$cluster_quality)
#   cluster mean_R2_own
# 1       1      0.8234
# 2       2      0.7891
# ...

# DÃ©tails RÂ² par variable
print(results$R2_details)
```
---
## ğŸ¨ Shiny Application
---
content shiny 
---
## ğŸ§ª Tests

Le package inclut **203 tests unitaires** couvrant toutes les fonctionnalitÃ©s.

### ExÃ©cuter les tests

```r
# Tous les tests
devtools::test()

# Tests spÃ©cifiques
testthat::test_file("tests/testthat/test-kmeans.R")
testthat::test_file("tests/testthat/test-acm_cah.R")
testthat::test_file("tests/testthat/test-varclus.R")
```

### RÃ©sultats attendus

```
âœ” | 68 | acm_cah
âœ” | 57 | kmeans
âœ” | 78 | varclus
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ FAIL 0 | WARN 0 | SKIP 1 | PASS 203 ]
```

---

## â“ Getting Help

### Function help 

```r
# Help for a class 
?KMeansVariablesQuant
?ClustModalities
?VarClus

# Help for a dataset
?crime
?vote
?uscrime
```

---

## ğŸ› ï¸ Package structure 


Add tree

---

## ğŸ‘¥ Authors

- **Maissa Lajimi** 
- **Yassine Cheniour** 
- **Lamia Hatem** 

Master 2 Data Science (SISE), University of Lyon 2

## ğŸ“„ License

This project is licensed under the MIT License.
